<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Ziteng Cui</title>
  
  <meta name="author" content="Ziteng Cui">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Ziteng Cui (Â¥îÂ≠êËó§)</name>
              </p>
              <p>I am now a first year PHD student at <a href="https://www.rcast.u-tokyo.ac.jp/ja/index.html">The University of Tokyo</a>, where I supervised by <a href="https://www.mi.t.u-tokyo.ac.jp/harada/">Prof. Tatsuya Harada</a>, before that I got my master degree in <a href="https://en.sjtu.edu.cn/">Shanghai Jiao Tong University</a>.
              </p>
              <p>
                I mainly work on Computational Photography, Vision Robustness and Vision Fariness.
              </p>
              <p style="text-align:center">
                <a href="cui@mi.t.u-tokyo.ac.jp">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.co.id/citations?user=niXIRXgAAAAJ&hl=id">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/cuiziteng/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/photo.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/photo.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Selected Publications</heading>
              <p>
                I'm now interested in low-level vision, vision robustness, low-light vision tasks and physics modeling. 
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
		
	  <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/IAT.png" alt="IAT" width="170" height="140">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2205.14871.pdf">
                <papertitle>You Only Need 90K Parameters to Adapt Light: A Light Weight Transformer for Image Enhancement and Exposure Correction</papertitle>
              </a>
              <br>
              <strong>Ziteng Cui</strong>,
	      Kunchang Li,
	      Lin Gu, Shenghan Su, Peng Gao, Zhengkai Jiang, Yu Qiao, Tatsuya Harada.
              <br>
              <em>BMVC</em>, 2022 &nbsp 
              <br>
              <a href="https://arxiv.org/abs/2205.14871">arxiv</a> /
              <a href="https://github.com/cuiziteng/Illumination-Adaptive-Transformer">code</a> /
	      <a href="data/IAT.bib">bibtex</a> /
	      <a href="https://twitter.com/PINTO03091/status/1551587870175281152">video demo</a>
              <p></p>
              <p>A super light-weight (only 90k+ parameters) transformer-based network (Illumination Adaptive Transformer), for real time image enhancement and exposure correction.</p>
            </td>
          </tr>
	
	  <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/restoredet.png" alt="ECCV_Restoredet" width="170" height="140">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="">
                <papertitle>Exploring Resolution and Degradation Clues as Self-supervised Signal for Low Quality Object Detection</papertitle>
              </a>
              <br>
              <strong>Ziteng Cui</strong>,
	      Yingying Zhu,
	      Lin Gu, Guo-Jun Qi, Xiaoxiao Li, Renrui Zhang, Zenghui Zhang, Tatsuya Harada.
              <br>
              <em>ECCV</em>, 2022 &nbsp 
              <br>
              <a href="https://arxiv.org/abs/2208.03062">arxiv</a> /
              <a href="https://github.com/cuiziteng/ECCV_AERIS">code</a> / 
	      <a href="data/ECCV_AERIS.bib">bibtex</a>
              <p></p>
              <p>Combination the object detector with self-supervised super-resolution, for robust detection under various degradation conditions.</p>
            </td>
          </tr>
		
	 

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/low_after.png" alt="ICCV_MAET" width="170" height="140">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Cui_Multitask_AET_With_Orthogonal_Tangent_Regularity_for_Dark_Object_Detection_ICCV_2021_paper.pdf">
                <papertitle>Multitask AET with Orthogonal Tangent Regularity for Dark Object Detection</papertitle>
              </a>
              <br>
              <strong>Ziteng Cui</strong>,
	      Guo-Jun Qi,
	      Lin Gu, Shaodi You, Zenghui Zhang, Tatsuya Harada.
              <br>
              <em>ICCV</em>, 2021 &nbsp 
              <br>
              <a href="https://arxiv.org/abs/2205.03346">arxiv</a> /
              <a href="https://github.com/cuiziteng/ICCV_MAET">code</a> /
	      <a href="data/MAET_ICCV.bib">bibtex</a> /
	      <a href="https://drive.google.com/file/d/14FHLdtGbtoNYx64GaGjPAlXWeU61f8-v/view?usp=sharing">poster</a> 
              <p></p>
              <p>Using Camera-ISP pipeline for low-light image synthetic, then using self-supervised learning to improving the performance of low-light condition object detection.</p>
            </td>
          </tr>
	

        </tbody></table>

				
        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Misc</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
					
		
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/SJTU.png" alt="SJTU" width="160" height="160">
            </td>
            <td width="75%" valign="center">
              <a>National Scholarship (Highest Scholarship in China)</a>
              <br>
              <a>Excellent Graduate Student</a>
              <br>
            </td>
          </tr>
					
					
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                This website is borrow from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
                <br>
                Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
